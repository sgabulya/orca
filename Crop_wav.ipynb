{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import soundfile as sf\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose file to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c884667ef3724ac5b4dc37fa9b4c680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='CSV files:', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory='/Users/saroltagabulya/git/Orca/timestamp_csv'\n",
    "wavs=glob.glob('*.csv')\n",
    "file=[]\n",
    "\n",
    "dropdown=widgets.Dropdown(\n",
    "    options=wavs,\n",
    "    description='CSV files:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def dropdown_eventhandler(change):\n",
    "    file.clear()\n",
    "    file.append(change.new)\n",
    "    print(change.new)\n",
    "dropdown.observe(dropdown_eventhandler, names='value')\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-479cb27557da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Also extract recording name for later use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecording_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "filename = directory + file[0]\n",
    "time_stamps=pd.read_csv(filename, index_col=0)\n",
    "\n",
    "# Also extract recording name for later use\n",
    "recording_name=file[0][12:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check sampling rate manually in the metadata file and set below in Hz! \n",
      "100000\n",
      "Please check reference value in the files README and set below in uPa! \n",
      "0\n",
      "Please check calibration value in the files README and set below! \n",
      " what does the fullscale voltage correspond to in Pa? \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "# Set sample rate\n",
    "try:\n",
    "    wave_file=wave.open(file[0], \"rb\")\n",
    "    sample_rate = wave_file.getframerate()\n",
    "except:\n",
    "    sample_rate=int(input('Please check sampling rate manually in the metadata file and set below in Hz! \\n'))\n",
    "    \n",
    "# Set reference value\n",
    "ref_value=int(input('Please check reference value in the files README and set below in uPa! \\n'))\n",
    "\n",
    "# Calibration value\n",
    "cal_value=int(input('Please check calibration value in the files README and set below! \\n what does the fullscale voltage correspond to in Pa? \\n '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(recording_name + '.wav', sr=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets & offsets in csv are in seconds => Convert to samples by multiplying them with the fs\n",
    "\n",
    "second * fs = samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps['onset_samples']=time_stamps.onset.apply(lambda x: int(round(x*sr)))\n",
    "time_stamps['offset_samples']=time_stamps.offset.apply(lambda x: int(round(x*sr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for cropping wav and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./call_segments/' + recording_name)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_call(row, y, sr, recording_name):\n",
    "    call_filename= recording_name + '_' + str(row.onset_samples) + '_' + str(row.offset_samples) + '.wav'\n",
    "    call=y[row.onset_samples: row.offset_samples]\n",
    "    call_path='./call_segments/' + recording_name +'/' +  call_filename\n",
    "    sf.write(call_path, call, sr) \n",
    "    return call_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps['call_wav']=time_stamps.apply(lambda x: crop_call(x, y, sr, recording_name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata(time_stamps, sample_rate, ref_value, cal_value, researcher):\n",
    "    meta_df=pd.DataFrame()\n",
    "    \n",
    "    meta_df['segment_file']=time_stamps.apply(lambda x: x.call_wav.split('/')[-1], axis=1)\n",
    "    meta_df['wav_origin']=time_stamps.apply(lambda x: x.call_wav.split('/')[-1].split('_')[0] + '.wav', axis=1)\n",
    "    meta_df['onset_seconds']=time_stamps.onset\n",
    "    meta_df['offset_seconds']=time_stamps.offset\n",
    "    meta_df['duration_seconds']=time_stamps.offset-time_stamps.onset \n",
    "    meta_df['onset_samples']=time_stamps.onset_samples\n",
    "    meta_df['offset_samples']=time_stamps.offset_samples\n",
    "    meta_df['duration_samples']=time_stamps.offset_samples-time_stamps.onset_samples\n",
    "    meta_df['sample_rate']=pd.Series([sample_rate]*len(time_stamps))\n",
    "    meta_df['ref_value']=pd.Series([ref_value]*len(time_stamps))\n",
    "    meta_df['cal_value']=pd.Series([cal_value]*len(time_stamps))\n",
    "    meta_df['researcher']=pd.Series(['SG']*len(time_stamps))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher='SG'\n",
    "prep_metadata(time_stamps, sample_rate, ref_value, cal_value, researcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-02-04--10-14-06--00-16-35--BC'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.wav_origin[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metadata(row, output_dir):\n",
    "    \n",
    "    #Prepare filename\n",
    "    metafilename=row.wav_origin[:-4] + '/'+ row.segment_file[:-3]  + 'yml'\n",
    "    \n",
    "    #Convert row to dictionary\n",
    "    d = {k: (v if type(v).__module__ != 'numpy' else v.item()) for k,v in row.to_dict().items()}\n",
    "    \n",
    "    \n",
    "    with open(output_dir + metafilename, 'w') as outfile:\n",
    "        yaml.dump(d, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir='./call_segments/' \n",
    "meta_df.apply(lambda x: write_metadata(x, output_dir), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv under new name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps.to_csv('call_data_' + recording_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafile=''\n",
    "\n",
    "with open(metafile) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    metadata = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "print(metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
